
> Active AI research areas 


-------------

RL Research Directions

- Research direction
1, systematic, comparative study of deep RL algorithms, is about reproducibility, and under
the surface, about stability and convergence properties of deep RL algorithms. 

- Research direction
2, ”solve” multi-agent problems, is usually about sample efficiency, sparse reward, stability, nonstationarity,
and convergence in a large-scale, complex setting, a frontier in AI research. 

- Research
direction 3, learn from entities, but not just raw inputs, is about sample efficiency, sparse reward,
and interpretability, by incorporating more knowledge, structure, and inductive bias. 

- Research direction 4, design an optimal representation for RL.

- Research direction 5, AutoRL .

- Research direction 6, develop killer applications for (deep) RL, are about the whole RL problem, about all
issues in RL, like credit assignment, sparse reward, time/space/sample efficiency, accuracy, stability,
convergence, interpretability, safety, scalability, robustness, simplicity, etc, from different angles
of representation, automation, and application, respectively. 

----------------
Challenges of DL:
 
- Big data analytics using Deep Learning
- Scalability of DL approaches
- Ability to generate data which is important where data is
not available for learning the system (especially for
computer vision task such as inverse graphics).
- Energy efficient techniques for special purpose devices
including mobile intelligence, FPGAs, and so on.
- Multi-task and transfer learning (generalization) or
multi-module learning. This means learning from
different domains or with different models together.
- Dealing with causality in learning.

-----------

- Transfer Learning

- AI hardware

- ML/DL/RL platforms

- Object detection

- Video understanding

- Visual Scene Understanndig

- Goal Oriented RL

- Multiagent RL

- RL builds own models

- Fairness in machine learning

- Explainability in ML models

- Advesarial attacks on DL networks 

- AutoML(meta-learning) , https://sites.google.com/site/automl2018icml/ , http://metalearning.ml/2018/ , https://sites.google.com/view/continual2018 , https://sites.google.com/view/llarla2018/home , https://bair.berkeley.edu/blog/2017/07/18/learning-to-learn/

- Decentralized data sharing and training

- Generative models

-  Learning from less data and building smaller models

-  Learning in simulated environments

-  Evolutionary Computing

-  Word embeddings

 
-------------

- [OpenAI: Requests for Research](https://openai.com/requests-for-research/#parallel-trpo)
- [State of AI](https://www.stateof.ai/?utm_campaign=nathan.ai%20newsletter&utm_medium=email&utm_source=Revue%20newsletter)
- [6 areas of AI and machine learning to watch closely](https://medium.com/@NathanBenaich/6-areas-of-artificial-intelligence-to-watch-closely-673d590aa8aa)
- [AI in 2018 for researchers](https://blog.goodaudience.com/ai-in-2018-for-researchers-8955df0caaf9)
- [Supervised Learning cheatsheet](https://stanford.edu/~shervine/teaching/cs-229/cheatsheet-supervised-learning.html)
- [Deep Learning cheatsheet](https://stanford.edu/~shervine/teaching/cs-229/cheatsheet-deep-learning.html)
- [Unsupervised Learning cheatsheet](https://stanford.edu/~shervine/teaching/cs-229/cheatsheet-unsupervised-learning.html)
- [Machine Learning tips and tricks cheatsheet](https://stanford.edu/~shervine/teaching/cs-229/cheatsheet-machine-learning-tips-and-tricks.html)
- [IBM code patterns](https://developer.ibm.com/code/patterns/)
- [fast-style-transfer](https://github.com/lengstrom/fast-style-transfer)
- [tensorflow-fcn](https://github.com/MarvinTeichmann/tensorflow-fcn)
- [SSD-Tensorflow](https://github.com/balancap/SSD-Tensorflow)
- [FastMaskRCNN](https://github.com/CharlesShang/FastMaskRCNN)
- [reinforcement-learning](https://github.com/dennybritz/reinforcement-learning)
- [Creative Applications of Deep Learning with TensorFlow](https://www.kadenze.com/courses/creative-applications-of-deep-learning-with-tensorflow-iv/info)
- [Deep Learning: Which Loss and Activation Functions should I use?](https://medium.com/@srnghn/deep-learning-which-loss-and-activation-functions-should-i-use-ac02f1c56aa8)
- [AI in 2018 for developers](https://blog.goodaudience.com/ai-in-2018-for-researchers-8955df0caaf9)
- [image-kernels](http://setosa.io/ev/image-kernels/)
- [Over 150 of the Best Machine Learning, NLP, and Python Tutorials I’ve Found](https://medium.com/machine-learning-in-practice/over-150-of-the-best-machine-learning-nlp-and-python-tutorials-ive-found-ffce2939bd78)
- [ml-cheatsheet](https://github.com/bfortuner/ml-cheatsheet)
- [int8](https://int8.io/)

--------
